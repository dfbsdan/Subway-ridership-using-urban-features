{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutputs:\\n  ./network_nodes.json (pd.Dataframe with cols: 'station_id', 'station_name_ENG', 'lat', 'lng')\\n\\n  ./ridership.npy (np.ndarray)              shape: (M, N, H, 7, 2)\\n  ./urban_features.npy (np.ndarray)         shape: (M, N, D)\\n  ./adjacency.npy (np.ndarray)              shape: (N, N)\\n  ./spatial_embeddings.npy (np.ndarray)     shape: (N, D)\\n\\nWhere: \\n  M: Months (2017-01 to 2020-12)\\n  N: Stations\\n  D: Any number of dimensions\\n  H: Timesteps per day: ('00~06', '06~10', '10~16', '16~21', '21~00')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "outputs:\n",
    "  ./network_nodes.json (pd.Dataframe with cols: 'station_id', 'station_name_ENG', 'lat', 'lng')\n",
    "\n",
    "  ./ridership.npy (np.ndarray)              shape: (M, N, H, 7, 2)\n",
    "  ./urban_features.npy (np.ndarray)         shape: (M, N, D)\n",
    "  ./adjacency.npy (np.ndarray)              shape: (N, N)\n",
    "  ./spatial_embeddings.npy (np.ndarray)     shape: (N, D)\n",
    "\n",
    "Where: \n",
    "  M: Months (2017-01 to 2020-12)\n",
    "  N: Stations\n",
    "  D: Any number of dimensions\n",
    "  H: Timesteps per day: ('00~06', '06~10', '10~16', '16~21', '21~00')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def __load_network(nodes_path: str, adjacency_path: str):\n",
    "  nodes: pd.DataFrame = pd.read_json(nodes_path)\n",
    "  nodes.set_index('station_id', inplace=True, verify_integrity=True)\n",
    "  nodes = gpd.GeoDataFrame(\n",
    "    nodes, geometry=gpd.points_from_xy(x=nodes.lng, y=nodes.lat), crs='EPSG:4326'\n",
    "  )\n",
    "  adjacency: np.ndarray = np.load(adjacency_path)\n",
    "  return (nodes, adjacency)\n",
    "\n",
    "def __load_hourly_ridership(path: str):\n",
    "  df: pd.DataFrame = pd.read_feather(path)\n",
    "  df.set_index(['date', 'time', 'station_id'], inplace=True, verify_integrity=True)\n",
    "  return df\n",
    "\n",
    "def __load_poi(path: str):\n",
    "  df: pd.DataFrame = pd.read_feather(path)\n",
    "  df.set_index(['date', 'station_id'], inplace=True, verify_integrity=True)\n",
    "  return df\n",
    "\n",
    "def __load_building_use(path: str):\n",
    "  df: pd.DataFrame = pd.read_feather(path)\n",
    "  df.set_index(['date', 'station_id'], inplace=True, verify_integrity=True)\n",
    "  return df\n",
    "\n",
    "def __load_lte(path: str):\n",
    "  df: pd.DataFrame = pd.read_feather(path)\n",
    "  df.set_index(['date', 'time', 'station_id'], inplace=True, verify_integrity=True)\n",
    "  return df.groupby(level=['date', 'station_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ts = ['00~06', '06~10', '10~16', '16~21', '21~00']\n",
    "weekdays = range(7)\n",
    "years = [2017, 2018, 2019, 2020]\n",
    "months = range(1, 13)\n",
    "data_path = '.'\n",
    "\n",
    "def __filter_stations(df1: pd.DataFrame, df2: pd.DataFrame, df3: pd.DataFrame, df4: pd.DataFrame, df5: pd.DataFrame):\n",
    "  return set(df1.index.unique('station_id')).intersection(\n",
    "    set(df2.index.unique('station_id')),\n",
    "    set(df3.index.unique('station_id')),\n",
    "    set(df4.index.unique('station_id')),\n",
    "    set(df5.index.unique('station_id'))\n",
    "  )\n",
    "\n",
    "def filter_df(df: pd.DataFrame, st_ids: set, reduce_sum: bool, time=False):\n",
    "  df = df[df.index.get_level_values('station_id').isin(st_ids)].copy()\n",
    "  df.reset_index(inplace=True)\n",
    "  df['date'] = pd.to_datetime(df['date'])\n",
    "  df['year'] = df['date'].dt.year\n",
    "  df = df[df['year'].isin(years)]\n",
    "  df['month'] = df['date'].dt.month\n",
    "  if time:\n",
    "    df['weekday'] = df['date'].dt.dayofweek\n",
    "    group_by = ['year', 'month', 'station_id', 'time', 'weekday']\n",
    "    fixed_idx = pd.MultiIndex.from_product([years, months, sorted(list(st_ids)), daily_ts, weekdays], names=group_by)\n",
    "  else:\n",
    "    group_by = ['year', 'month', 'station_id']\n",
    "    fixed_idx = pd.MultiIndex.from_product([years, months, sorted(list(st_ids))], names=['year', 'month', 'station_id'])\n",
    "  df.drop('date', axis=1, inplace=True)\n",
    "  df = df.groupby(by=group_by)\n",
    "  df = df.sum() if reduce_sum else df.mean()\n",
    "  df = df.reindex(fixed_idx, copy=False, fill_value=0)\n",
    "  return df\n",
    "\n",
    "def filter_data():\n",
    "  subway, adj = __load_network(data_path + '/datasets/subway/network_nodes.json', data_path + '/datasets/subway/network_adjacency.npy')\n",
    "  ridership = __load_hourly_ridership(data_path + '/datasets/subway/ridership_hourly.ftr')\n",
    "  poi = __load_poi(data_path + '/datasets/poi/poi.ftr')\n",
    "  bu = __load_building_use(data_path + '/datasets/building_use/building_use.ftr')\n",
    "  lte = __load_lte(data_path + '/datasets/lte/lte.ftr')\n",
    "  st_ids = __filter_stations(subway, ridership, poi, bu, lte)\n",
    "  # subway nodes\n",
    "  subway = subway[subway.index.get_level_values('station_id').isin(st_ids)]\n",
    "  subway.sort_index(inplace=True)\n",
    "  subway.reset_index(inplace=True)\n",
    "  subway[['station_id', 'station_name_ENG', 'lat', 'lng']].to_json(data_path + '/network_nodes.json')\n",
    "  del subway\n",
    "  # urban features\n",
    "  poi = filter_df(poi, st_ids, False)\n",
    "  bu = filter_df(bu, st_ids, False)\n",
    "  lte = filter_df(lte, st_ids, False)\n",
    "  uf = pd.concat([poi, bu, lte], axis=1, join='inner') # (MxN, F)\n",
    "  del poi\n",
    "  del bu\n",
    "  del lte\n",
    "  MxN, F = uf.shape\n",
    "  uf = uf.to_numpy()\n",
    "  N = len(st_ids)\n",
    "  M = MxN / N\n",
    "  assert M % 1 == 0\n",
    "  M = int(M)\n",
    "  assert M == 12 * len(years)\n",
    "  uf = uf.reshape((M, N, F)) # t: Month\n",
    "  np.save(data_path + '/urban_features.npy', uf)\n",
    "  del uf\n",
    "  # ridership\n",
    "  ridership = filter_df(ridership, st_ids, False, True) # (MxNxHx7, 2)\n",
    "  MxNxHx7_2 = ridership.shape\n",
    "  H = len(daily_ts)\n",
    "  assert MxNxHx7_2 == (M*N*H*7, 2)\n",
    "  ridership = ridership.to_numpy()\n",
    "  ridership = ridership.reshape((M, N, H, 7, 2))\n",
    "  np.save(data_path + '/ridership.npy', ridership)\n",
    "  del ridership\n",
    "  # adjacency\n",
    "  st_ids = sorted(list(st_ids))\n",
    "  adj = adj[st_ids][:,st_ids]\n",
    "  np.save(data_path + '/adjacency.npy', adj)\n",
    "  del adj\n",
    "  # spatial embeddings\n",
    "  f = open('./SE.txt', mode='r')\n",
    "  lines = f.readlines()\n",
    "  temp = lines[0].split(' ')\n",
    "  D = int(temp[1])\n",
    "  SE = np.zeros(shape=(N,D), dtype=np.float32)\n",
    "  st_to_se = dict()\n",
    "  for line in lines[1:]:\n",
    "    temp = line.split(' ')\n",
    "    st_id = int(temp[0])\n",
    "    if st_id in st_ids:\n",
    "      assert not st_id in st_to_se\n",
    "      st_to_se[st_id] = temp[1:]\n",
    "  st_to_se = sorted(list(st_to_se.items()), key=lambda tup: tup[0])\n",
    "  assert len(st_to_se) == N\n",
    "  for i, (_, se) in enumerate(st_to_se):\n",
    "    SE[i] = se\n",
    "  np.save(data_path + '/spatial_embeddings.npy', SE)\n",
    "\n",
    "filter_data()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
