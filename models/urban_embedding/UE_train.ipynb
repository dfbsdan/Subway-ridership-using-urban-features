{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "sys.path.extend(['/content/drive/MyDrive/KAIST/thesis/models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "from UE import TrVAE\n",
    "\n",
    "dir_path = '/content/drive/MyDrive/KAIST/thesis'\n",
    "data_path = dir_path + '/data'\n",
    "reconstruction_loss = 'MAE' # 'MSE'\n",
    "save_path = dir_path + f'/models/urban_embedding/UE_{reconstruction_loss}.model'\n",
    "learning_rate = 0.001\n",
    "decay_epoch = 5\n",
    "bn_decay = 0.9\n",
    "patience = 10\n",
    "max_epoch = 1000\n",
    "batch_size = 16\n",
    "offs_months = 7\n",
    "rec_loss_weight = 1000\n",
    "decay_rate = 0.7\n",
    "Q = 1 # output sequence length\n",
    "D = 64 # latent space dim\n",
    "L = 3 # number of STAtt blocks in the encoder/decoder\n",
    "K = 8 # number of attention heads\n",
    "d = 8 # dimension of each attention head outputs\n",
    "\n",
    "class CustomDataset(Sequence):\n",
    "  def __init__(self, data: np.ndarray, batch_sz: int, Q: int) -> None:\n",
    "    super().__init__()\n",
    "    N, M, _ = data.shape\n",
    "    self.data = data\n",
    "    self.N = N\n",
    "    self.Q = Q\n",
    "    self.P_max = M - offs_months - Q + 1\n",
    "    assert self.P_max > 0\n",
    "    self.batch_sz = batch_sz\n",
    "    self.len = math.ceil((N * self.P_max) / batch_sz)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n",
    "  def __get_xy(self, idx: int):\n",
    "    n = idx // self.P_max\n",
    "    if n >= self.N:\n",
    "      return None\n",
    "    P = idx % self.P_max + 1\n",
    "    x = self.data[n, :P, :] # (P, F)\n",
    "    x = tf.pad(x, [[self.P_max-P, 0], [0,0]], 'CONSTANT') # (P_max, F)\n",
    "    y_start = P + offs_months - 1\n",
    "    y = self.data[n, y_start:y_start + self.Q, :] # (Q, F)\n",
    "    y = np.concatenate((x, y), axis=0) # (P_max+Q, F)\n",
    "    return x, y\n",
    "\n",
    "  def __getitem__(self, batch_idx: int):\n",
    "    assert batch_idx < self.len\n",
    "    start_idx = batch_idx * self.batch_sz\n",
    "    batch = [self.__get_xy(idx) for idx in range(start_idx, start_idx + self.batch_sz)]\n",
    "    batch = [xy for xy in batch if xy != None]\n",
    "    return tf.stack([x for x, _ in batch]), tf.stack([y for _, y in batch])\n",
    "\n",
    "# saves and evaluates the model every time the validation loss improves\n",
    "class BestValLossCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, test: np.ndarray, save_path: str):\n",
    "    self.test = CustomDataset(test, batch_size, Q)\n",
    "    self.save_path = save_path\n",
    "    self.best_val_loss = np.Inf\n",
    "  \n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    cur_val_loss = logs.get(\"val_loss\")\n",
    "    if cur_val_loss < self.best_val_loss:\n",
    "      self.best_val_loss = cur_val_loss\n",
    "      self.model.save_weights(self.save_path, overwrite=True)\n",
    "      if epoch >= 10:\n",
    "        self.model.evaluate(\n",
    "          self.test,\n",
    "          verbose=1,\n",
    "        )\n",
    "\n",
    "class MeanELBOLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self, mean, std) -> None:\n",
    "    super().__init__()\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "    self.kl = tf.keras.losses.KLDivergence()\n",
    "    reconst_losses = {\n",
    "      'MSE': tf.keras.losses.MeanSquaredError, \n",
    "      'MAE': tf.keras.losses.MeanAbsoluteError\n",
    "    }\n",
    "    self.reconst = reconst_losses[reconstruction_loss]()\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    y_true = y_true * self.std + self.mean\n",
    "    y_pred = y_pred * self.std + self.mean\n",
    "    # (batch, P+Q, F)\n",
    "    return self.kl(y_true, y_pred) + rec_loss_weight * self.reconst(y_true, y_pred)\n",
    "\n",
    "class CustomMetric(tf.keras.metrics.Metric):\n",
    "  def __init__(self, mean: float, std: float, name: str) -> None:\n",
    "    super(CustomMetric, self).__init__(name=name)\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "    metrics = {\n",
    "      'MAE': tf.metrics.MeanAbsoluteError, \n",
    "      'MSE': tf.metrics.MeanSquaredError,\n",
    "      'RMSE': tf.metrics.RootMeanSquaredError,\n",
    "      'KL': tf.metrics.KLDivergence,\n",
    "    }\n",
    "    self.main = metrics[name]()\n",
    "  \n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    self.main.update_state(y_true * self.std + self.mean, y_pred * self.std + self.mean, sample_weight)\n",
    "  \n",
    "  def result(self):\n",
    "    return self.main.result()\n",
    "\n",
    "def train_and_test(model: tf.keras.Model, \n",
    "    train: np.ndarray, val: np.ndarray, test: np.ndarray):\n",
    "  N_train = train.shape[0]\n",
    "  mean = train.mean()\n",
    "  std = train.std()\n",
    "  train = (train - mean) / std\n",
    "  val = (val - mean) / std\n",
    "  test = (test - mean) / std\n",
    "  model.compile(\n",
    "    loss=MeanELBOLoss(mean, std),\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "      learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        learning_rate,\n",
    "        decay_steps=decay_epoch * (N_train*(M-offs_months)) // batch_size,\n",
    "        decay_rate=decay_rate, \n",
    "        staircase=True\n",
    "      )\n",
    "    ),\n",
    "    metrics=[\n",
    "      CustomMetric(mean, std, 'MAE'),\n",
    "      CustomMetric(mean, std, 'MSE'),\n",
    "      CustomMetric(mean, std, 'RMSE'),\n",
    "      CustomMetric(mean, std, 'KL'),\n",
    "    ]\n",
    "  )\n",
    "  model.fit(\n",
    "    CustomDataset(train, batch_size, Q),\n",
    "    epochs=max_epoch,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    validation_data=CustomDataset(val, batch_size, Q),\n",
    "    callbacks=[\n",
    "      tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        mode='min'\n",
    "      ),\n",
    "      BestValLossCallback(test, save_path),\n",
    "    ],\n",
    "  )\n",
    "\n",
    "# urban features\n",
    "UF: np.ndarray = np.load(data_path + '/urban_features.npy') # (M, N, F)\n",
    "M, N, F = UF.shape\n",
    "P_max = M - offs_months - Q + 1\n",
    "UF = np.transpose(UF, (1, 0, 2)) # (N, M, F)\n",
    "train_split = int(0.7 * len(UF))\n",
    "val_split = int(0.1 * len(UF))  \n",
    "train = UF[:train_split] # (N_train, M, F)\n",
    "val = UF[train_split:train_split + val_split] # (N_val, M, F)\n",
    "test = UF[train_split + val_split:] # (N_test, M, F)\n",
    "print(f'train: {train.shape}, val: {val.shape}, test: {test.shape}')\n",
    "model = TrVAE(Q=Q, D=D, L=L, K=K, d=d, F=F, P_max=P_max)\n",
    "train_and_test(model, train, val, test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
